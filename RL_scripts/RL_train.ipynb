{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Increasingly difficult Environment\n",
    "- Positive reward for populating increasingly \"deep\" blending tanks ?\n",
    "- RL for chem sched paper (https://arxiv.org/pdf/2203.00636)\n",
    "- Masking (https://sb3-contrib.readthedocs.io/en/master/modules/ppo_mask.html, https://arxiv.org/pdf/2006.14171)\n",
    "    - Adding binary decision variables ?g  \n",
    "    - Requires discrete action space (only integer flows -> treated as categories ?)\n",
    "    - masking: disable incoming flows (resp. outgoing flows) for tanks at UB inv limit (resp. LB inv. limit), disable selling/buying when available = 0\n",
    "    - multiple envs with multiple agents ? (MARL, https://arxiv.org/pdf/2103.01955)\n",
    "        - Predict successive pipelines (\"source > blend\" then \"blend > blend\" (as many as required) then \"blend > demand\")\n",
    "        - Each agent has access to the whole state\n",
    "        - Action mask is derived from the previous agent's actions (0 if inventory at bounds or incoming flow already reserved, else 1)\n",
    "        - https://github.com/Rohan138/marl-baselines3/blob/main/marl_baselines3/independent_ppo.py\n",
    "- Safe RL: (https://proceedings.mlr.press/v119/wachi20a/wachi20a.pdf)\n",
    "    - \"Unsafe state\" ? > Do not enforce constraints strictly, instead opt for early episode termination to show which states are unsafe ? \n",
    "    - Implementations:\n",
    "        - https://pypi.org/project/fast-safe-rl/#description (Policy optimizers)\n",
    "        - https://github.com/PKU-Alignment/safety-gymnasium/tree/main/safety_gymnasium (environments; \"cost\" ?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Masking: Discretization of action space is too slow/might not work -> Need to implement masking for continuous action space\n",
    "- Recurrent policy makes the most sense ? (window of demand forecasts)\n",
    "- https://www.reddit.com/r/reinforcementlearning/comments/17l5b47/invalid_action_masking_when_action_space_is/\n",
    "    - Suggestion of autoregressive model for having constraints respected: one predicted action is input to a second model\n",
    "    - Suggestion of editing the distribution in such a way that the constraint is respected\n",
    "- https://www.sciencedirect.com/science/article/pii/S0098135420301599\n",
    "    - Choice of ELU activation ?\n",
    "    - Choice of NN size ?\n",
    "    - \"The feature engineering in the net inventory means the network does not have to learn these relationships itself, which did help speed training.\" ?\n",
    "- Simplify the problem (remove tanks 5 to 8), find the optimal solution with Gurobi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Proportional penalty instead of flat\n",
    "- Solution pool from Gurobi for data generation\n",
    "- Uniformize the distribution profile\n",
    "    - Idea is to remove start/end of episode effects to make the distribution simpler (see photo)\n",
    "    - -> Simulate infinite sup/dem profile\n",
    "    - -> simulate env with 12 time periods, only use the first 6 for the data, then do the same by shifting by 12.\n",
    "        - -> Need to implement non-zero initial inv states for both gym and gurobi\n",
    "\n",
    "- Clarify how DT works at inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "try:\n",
    "    print(curr_dir)\n",
    "except:\n",
    "    curr_dir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "    os.chdir(curr_dir)\n",
    "    print(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mth\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PPO, DDPG, SAC, TD3\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmonitor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Monitor\n",
      "File \u001b[1;32mc:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\blendv2\\lib\\site-packages\\torch\\__init__.py:2143\u001b[0m\n\u001b[0;32m   2141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m library\n\u001b[0;32m   2142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m-> 2143\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations\n\u001b[0;32m   2145\u001b[0m \u001b[38;5;66;03m# Enable CUDA Sanitizer\u001b[39;00m\n\u001b[0;32m   2146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTORCH_CUDA_SANITIZER\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n",
      "File \u001b[1;32mc:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\blendv2\\lib\\site-packages\\torch\\_meta_registrations.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims_common\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SymBool, SymFloat, Tensor\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     _add_op_to_registry,\n\u001b[0;32m     11\u001b[0m     _convert_out_params,\n\u001b[0;32m     12\u001b[0m     global_decomposition_table,\n\u001b[0;32m     13\u001b[0m     meta_table,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpOverload\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _prim_elementwise_meta, ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\n",
      "File \u001b[1;32mc:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\blendv2\\lib\\site-packages\\torch\\_decomp\\__init__.py:245\u001b[0m\n\u001b[0;32m    241\u001b[0m             decompositions\u001b[38;5;241m.\u001b[39mpop(op, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;66;03m# populate the table\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecompositions\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_refs\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# See NOTE [Core ATen Ops]\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# list was copied from torch/_inductor/decomposition.py\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# excluding decompositions that results in prim ops\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# Resulting opset of decomposition is core aten ops\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\blendv2\\lib\\site-packages\\torch\\_decomp\\decompositions.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, cast, Iterable, List, Optional, Tuple, Union\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mprims\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims_common\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\blendv2\\lib\\site-packages\\torch\\_prims\\__init__.py:504\u001b[0m\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;66;03m# Elementwise unary operations\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m \u001b[38;5;28mabs\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_make_elementwise_unary_prim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimpl_aten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_promotion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOMPLEX_TO_FLOAT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m acos \u001b[38;5;241m=\u001b[39m _make_elementwise_unary_prim(\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macos\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    513\u001b[0m     impl_aten\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39macos,\n\u001b[0;32m    514\u001b[0m     doc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    515\u001b[0m     type_promotion\u001b[38;5;241m=\u001b[39mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[38;5;241m.\u001b[39mDEFAULT,\n\u001b[0;32m    516\u001b[0m )\n\u001b[0;32m    518\u001b[0m acosh \u001b[38;5;241m=\u001b[39m _make_elementwise_unary_prim(\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macosh\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    520\u001b[0m     impl_aten\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39macosh,\n\u001b[0;32m    521\u001b[0m     doc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    522\u001b[0m     type_promotion\u001b[38;5;241m=\u001b[39mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[38;5;241m.\u001b[39mDEFAULT,\n\u001b[0;32m    523\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\blendv2\\lib\\site-packages\\torch\\_prims\\__init__.py:472\u001b[0m, in \u001b[0;36m_make_elementwise_unary_prim\u001b[1;34m(name, type_promotion, **kwargs)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_elementwise_unary_prim\u001b[39m(\n\u001b[0;32m    466\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, type_promotion: ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    467\u001b[0m ):\n\u001b[0;32m    468\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m    Creates an elementwise unary prim.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_make_prim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m(Tensor self) -> Tensor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_prim_elementwise_meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_promotion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_promotion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRETURN_TYPE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNEW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\blendv2\\lib\\site-packages\\torch\\_prims\\__init__.py:320\u001b[0m, in \u001b[0;36m_make_prim\u001b[1;34m(schema, return_type, meta, impl_aten, doc, tags, use_old_custom_ops_api)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39malias_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m arg\u001b[38;5;241m.\u001b[39malias_info\u001b[38;5;241m.\u001b[39mis_write:\n\u001b[0;32m    319\u001b[0m             mutates_args\u001b[38;5;241m.\u001b[39mappend(arg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m--> 320\u001b[0m     prim_def \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprims::\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_prim_impl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutates_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmutates_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     prim_def\u001b[38;5;241m.\u001b[39mregister_fake(meta)\n\u001b[0;32m    328\u001b[0m _prim_packet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_ops\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mprims, name)\n",
      "File \u001b[1;32mc:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\blendv2\\lib\\site-packages\\torch\\_library\\custom_ops.py:142\u001b[0m, in \u001b[0;36mcustom_op\u001b[1;34m(name, fn, mutates_args, device_types, schema)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\blendv2\\lib\\site-packages\\torch\\_library\\custom_ops.py:123\u001b[0m, in \u001b[0;36mcustom_op.<locals>.inner\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m    121\u001b[0m     schema_str \u001b[38;5;241m=\u001b[39m schema\n\u001b[0;32m    122\u001b[0m namespace, opname \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 123\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mCustomOpDef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;66;03m# Check that schema's alias annotations match those of `mutates_args`.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     expected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\blendv2\\lib\\site-packages\\torch\\_library\\custom_ops.py:168\u001b[0m, in \u001b[0;36mCustomOpDef.__init__\u001b[1;34m(self, namespace, name, schema, fn)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_context_fn: Optional[Callable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_fn: Optional[Callable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lib \u001b[38;5;241m=\u001b[39m \u001b[43mget_library_allowing_overwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_namespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_to_dispatcher()\n\u001b[0;32m    170\u001b[0m OPDEFS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qualname] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\blendv2\\lib\\site-packages\\torch\\_library\\custom_ops.py:543\u001b[0m, in \u001b[0;36mget_library_allowing_overwrite\u001b[1;34m(namespace, name)\u001b[0m\n\u001b[0;32m    540\u001b[0m     OPDEF_TO_LIB[qualname]\u001b[38;5;241m.\u001b[39m_destroy()\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m OPDEF_TO_LIB[qualname]\n\u001b[1;32m--> 543\u001b[0m lib \u001b[38;5;241m=\u001b[39m \u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFRAGMENT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    544\u001b[0m OPDEF_TO_LIB[qualname] \u001b[38;5;241m=\u001b[39m lib\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lib\n",
      "File \u001b[1;32mc:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\blendv2\\lib\\site-packages\\torch\\library.py:69\u001b[0m, in \u001b[0;36mLibrary.__init__\u001b[1;34m(self, ns, kind, dispatch_key)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ns \u001b[38;5;129;01min\u001b[39;00m _reserved_namespaces \u001b[38;5;129;01mand\u001b[39;00m (kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEF\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFRAGMENT\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(ns, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is a reserved namespace. Please try creating a library with another name.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m frame \u001b[38;5;241m=\u001b[39m \u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     70\u001b[0m filename, lineno \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mfilename, frame\u001b[38;5;241m.\u001b[39mlineno\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm: Optional[Any] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_dispatch_library(kind, ns, dispatch_key, filename, lineno)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\traceback.py:211\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 211\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\traceback.py:366\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m--> 366\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mline\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\traceback.py:288\u001b[0m, in \u001b[0;36mFrameSummary.line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mline\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line \u001b[38;5;241m=\u001b[39m \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlineno\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\linecache.py:16\u001b[0m, in \u001b[0;36mgetline\u001b[1;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetline\u001b[39m(filename, lineno, module_globals\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 16\u001b[0m     lines \u001b[38;5;241m=\u001b[39m \u001b[43mgetlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m lineno \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(lines):\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m lines[lineno\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\linecache.py:47\u001b[0m, in \u001b[0;36mgetlines\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cache[filename][\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mupdatecache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mMemoryError\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m     clearcache()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\linecache.py:136\u001b[0m, in \u001b[0;36mupdatecache\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtokenize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    137\u001b[0m         lines \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\tokenize.py:392\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(filename):\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Open a file in read only mode using the encoding detected by\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    detect_encoding().\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 392\u001b[0m     buffer \u001b[38;5;241m=\u001b[39m \u001b[43m_builtin_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    394\u001b[0m         encoding, lines \u001b[38;5;241m=\u001b[39m detect_encoding(buffer\u001b[38;5;241m.\u001b[39mreadline)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from stable_baselines3 import PPO, DDPG, SAC, TD3\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.common.callbacks import *\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize, VecCheckNan\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.utils import safe_mean\n",
    "\n",
    "from envs import BlendEnv, flatten_and_track_mappings, reconstruct_dict\n",
    "from models import *\n",
    "from utils import *\n",
    "from math import exp, log\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(48_0114)|(49_0114)|(50_0114)|(51_0114)|(52_0114)|(53_0114)|(54_0114)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regex for tensorboard\n",
    "# Gives the current day's runs of the given config list\n",
    "from datetime import datetime\n",
    "L = []\n",
    "cfg_list = range(48, 55)\n",
    "for cfg in cfg_list:\n",
    "    L.append(\"(\" + str(cfg) + \"_\" + datetime.now().strftime('%m%d') + \")\")\n",
    "\"|\".join(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(/41/)|(/42/)|(/43/)|(/44/)|(/45/)|(/46/)|(/47/)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = []\n",
    "cfg_list = range(41, 48)\n",
    "for cfg in cfg_list:\n",
    "    L.append(\"(/\" + str(cfg) + \"/)\")\n",
    "\"|\".join(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## ENV CONFIGURATION ##############\n",
    "CONFIG = 65         # See /configs\n",
    "layout = \"simple\" # See /img\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./configs/{CONFIG}.yaml\", \"r\") as f:\n",
    "    s = \"\".join(f.readlines())\n",
    "    cfg = yaml.load(s, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg[\"custom_softmax\"]:\n",
    "    policytype = CustomMLP_ACP_simplest_softmax\n",
    "elif cfg[\"policytype\"] == \"MLP\":\n",
    "    policytype = \"MlpPolicy\"\n",
    "elif cfg[\"policytype\"] == \"MLPtanh\":\n",
    "    policytype = CustomMLP_ACP_simplest_tanh\n",
    "    \n",
    "optimizer_cls = eval(cfg[\"optimizer\"])\n",
    "\n",
    "if cfg[\"model\"][\"act_fn\"] == \"ReLU\":\n",
    "    act_cls = th.nn.ReLU\n",
    "elif cfg[\"model\"][\"act_fn\"] == \"tanh\":\n",
    "    act_cls = th.nn.Tanh\n",
    "elif cfg[\"model\"][\"act_fn\"] == \"sigmoid\":\n",
    "    act_cls = th.nn.Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections, action_sample = get_jsons(layout)\n",
    "sources, blenders, demands = get_sbp(connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 6\n",
    "if layout == \"base\":\n",
    "    sigma = {\"s1\":{\"q1\": 0.06}, \"s2\":{\"q1\": 0.26}}\n",
    "    sigma_ub = {\"p1\":{\"q1\": 0.16}, \"p2\":{\"q1\": 1}}\n",
    "    sigma_lb = {\"p1\":{\"q1\": 0}, \"p2\":{\"q1\": 0}}\n",
    "else:\n",
    "    sigma = {s:{\"q1\": 0.06} for s in sources}\n",
    "    sigma_ub = {d:{\"q1\": 0.16} for d in demands}\n",
    "    sigma_lb = {d:{\"q1\": 0} for d in demands}\n",
    "    \n",
    "s_inv_lb = {s: 0 for s in sources}\n",
    "s_inv_ub = {s: 999 for s in sources}\n",
    "d_inv_lb = {d: 0 for d in demands}\n",
    "d_inv_ub = {d: 999 for d in demands}\n",
    "betaT_d = {d: 1 for d in demands} # Price of sold products\n",
    "b_inv_ub = {j: 30 for j in blenders} \n",
    "b_inv_lb = {j: 0 for j in blenders}\n",
    "betaT_s = {s: cfg[\"env\"][\"product_cost\"]  for s in sources} # Cost of bought products\n",
    "\n",
    "if cfg[\"env\"][\"uniform_data\"]:\n",
    "    length = 13\n",
    "    if cfg[\"env\"][\"max_pen_violations\"] < 999:\n",
    "        length = 50\n",
    "        T = length\n",
    "        \n",
    "    tau0   = {s: [np.random.normal(20, 3) for _ in range(length)] for s in sources}\n",
    "    delta0 = {d: [np.random.normal(20, 3) for _ in range(length)] for d in demands}\n",
    "    \n",
    "else:\n",
    "    if cfg[\"env\"][\"shrink_data\"]:\n",
    "        tau0   = {s: [1, 1, 1, 0, 0, 0] for s in sources}\n",
    "        delta0 = {d: [0, 0, 0, 1, 1, 1] for d in demands}\n",
    "    else:\n",
    "        tau0   = {s: [10, 10, 10, 0, 0, 0] for s in sources}\n",
    "        delta0 = {d: [0, 0, 0, 10, 10, 10] for d in demands}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BlendEnv(v = False, T = T, layout = layout,\n",
    "               D = cfg[\"env\"][\"D\"], Q = cfg[\"env\"][\"Q\"], P = cfg[\"env\"][\"P\"], B = cfg[\"env\"][\"B\"], Z = cfg[\"env\"][\"Z\"], M = cfg[\"env\"][\"M\"],\n",
    "               reg = cfg[\"env\"][\"reg\"], reg_lambda = cfg[\"env\"][\"reg_lambda\"], L0_pen = cfg[\"env\"][\"L0_pen\"],\n",
    "               MAXFLOW = cfg[\"env\"][\"maxflow\"], alpha = cfg[\"env\"][\"alpha\"], beta = cfg[\"env\"][\"beta\"], \n",
    "               max_pen_violations = cfg[\"env\"][\"max_pen_violations\"], illeg_act_handling = cfg[\"env\"][\"illeg_act_handling\"],\n",
    "               connections = connections, action_sample = action_sample, \n",
    "               tau0 = tau0, delta0 = delta0, sigma = sigma,\n",
    "               sigma_ub = sigma_ub, sigma_lb = sigma_lb,\n",
    "               s_inv_lb = s_inv_lb, s_inv_ub = s_inv_ub,\n",
    "               d_inv_lb = d_inv_lb, d_inv_ub = d_inv_ub,\n",
    "               betaT_d = betaT_d, betaT_s = betaT_s,\n",
    "               b_inv_ub = b_inv_ub,\n",
    "               b_inv_lb = b_inv_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Monitor(env)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecNormalize(env, \n",
    "                   norm_obs=cfg[\"obs_normalizer\"], \n",
    "                   norm_reward=cfg[\"reward_normalizer\"])\n",
    "# env = VecCheckNan(env, raise_exception=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_kwargs = dict(\n",
    "    net_arch=[dict(pi = [cfg[\"model\"][\"arch_layersize\"]] * cfg[\"model\"][\"arch_n\"], \n",
    "                   vf = [cfg[\"model\"][\"arch_layersize\"]] * cfg[\"model\"][\"arch_n\"])],\n",
    "    activation_fn = act_cls,\n",
    "    # log_std_init = cfg[\"model\"][\"log_std_init\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlpPolicy\n"
     ]
    }
   ],
   "source": [
    "print(policytype)\n",
    "\n",
    "if optimizer_cls == PPO:\n",
    "    kwa = dict(policy = policytype, \n",
    "                env = env,\n",
    "                tensorboard_log = \"./logs2\",\n",
    "                clip_range = cfg[\"model\"][\"clip_range\"],\n",
    "                learning_rate = cfg[\"model\"][\"lr\"] if not cfg[\"model\"][\"lr_sched\"] else (lambda p: cfg[\"model\"][\"lr\"] + (cfg[\"model\"][\"lr_end\"] - cfg[\"model\"][\"lr\"]) * p),\n",
    "                ent_coef = cfg[\"model\"][\"ent_coef\"],\n",
    "                use_sde = cfg[\"model\"][\"use_sde\"],\n",
    "                batch_size = cfg[\"model\"][\"batch_size\"],\n",
    "                policy_kwargs = policy_kwargs)\n",
    "    \n",
    "else:\n",
    "    kwa = dict(policy = policytype, \n",
    "                env = env,\n",
    "                tensorboard_log = \"./logs2\",\n",
    "                batch_size = cfg[\"model\"][\"batch_size\"],\n",
    "                learning_rate = cfg[\"model\"][\"lr\"])\n",
    "\n",
    "model = optimizer_cls(**kwa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if cfg[\"starting_point\"]:\n",
    "    try:\n",
    "        cfg_start = int(cfg[\"starting_point\"])\n",
    "        bin_ = get_bin(cfg_start)\n",
    "        directory = f\"C:\\\\Users\\\\adame\\\\OneDrive\\\\Bureau\\\\CODE\\\\BlendingRL\\\\models\\\\{layout}\\\\{bin_}\\\\{cfg_start}\"\n",
    "        chosen, mod_chosen = \"\", 0\n",
    "        for f in os.listdir(directory):\n",
    "            mod_time = os.path.getmtime(os.path.join(directory, f))\n",
    "            if mod_time > mod_chosen:\n",
    "                chosen = os.path.join(f\"models\\\\{layout}\\\\{bin_}\\\\{cfg_start}\", f)\n",
    "        model.set_parameters(chosen)\n",
    "        \n",
    "    except ValueError:\n",
    "        model.set_parameters(cfg[\"starting_point\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO(learning_rate=lambda p: a + (b-a)* p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If batch_size = 64 and n_steps = 2048, then 1 epoch = 2048/64 = 32 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/simple/61-72/65/65_1225-1535'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_ = get_bin(cfg['id'])\n",
    "entcoef = str(model.ent_coef) if type(model) == PPO else \"\"\n",
    "cliprange = str(model.clip_range(0)) if type(model) == PPO else \"\"\n",
    "model_name = f\"models/{layout}/{bin_}/{cfg['id']}/{cfg['id']}_{datetime.now().strftime('%m%d-%H%M')}\"\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoggingCallbackPPO(BaseCallback):\n",
    "    def __init__(self, schedule_timesteps, start_log_std=2, end_log_std=-1, std_control = None, model_name = None, v = None):\n",
    "        super().__init__(verbose = 0)\n",
    "        self.std_control = std_control\n",
    "        \n",
    "        self.start_log_std = start_log_std\n",
    "        self.end_log_std = end_log_std\n",
    "        self.schedule_timesteps = schedule_timesteps\n",
    "        self.current_step = 0\n",
    "        # self.perfs = []\n",
    "        self.print_flag = False\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        self.pen_M, self.pen_B, self.pen_P, self.pen_reg = [], [], [], []\n",
    "        self.n_pen_M, self.n_pen_B, self.n_pen_P, self.n_pen_Q, self.pen_nv, self.pen_nv_counted = [], [], [], [], [], []\n",
    "        self.units_sold, self.units_bought, self.rew_sold, self.rew_depth = [], [], [], []\n",
    "        self.v = v\n",
    "        \n",
    "    def _on_rollout_end(self) -> None:\n",
    "        self.logger.record(\"penalties/in_out\",              sum(self.pen_M)/len(self.pen_M))\n",
    "        self.logger.record(\"penalties/buysell_bounds\",      sum(self.pen_B)/len(self.pen_B))\n",
    "        self.logger.record(\"penalties/tank_bounds\",         sum(self.pen_P)/len(self.pen_P))\n",
    "        \n",
    "        self.logger.record(\"penalties/n_in_out\",            sum(self.n_pen_M)/len(self.n_pen_M))\n",
    "        self.logger.record(\"penalties/n_buysell_bounds\",    sum(self.n_pen_B)/len(self.n_pen_B))\n",
    "        self.logger.record(\"penalties/n_tank_bounds\",       sum(self.n_pen_P)/len(self.n_pen_P))\n",
    "        self.logger.record(\"penalties/n_concentration\",     sum(self.n_pen_Q)/len(self.n_pen_Q))\n",
    "        self.logger.record(\"penalties/n_vltn\",              sum(self.pen_nv)/len(self.pen_nv))\n",
    "        self.logger.record(\"penalties/n_vltn_counted\",      sum(self.pen_nv_counted)/len(self.pen_nv_counted))\n",
    "        \n",
    "        self.logger.record(\"penalties/units_sold\",          sum(self.units_sold)/len(self.units_sold))\n",
    "        self.logger.record(\"penalties/units_bought\",        sum(self.units_bought)/len(self.units_bought))\n",
    "        self.logger.record(\"penalties/rew_sold\",            sum(self.rew_sold)/len(self.rew_sold))\n",
    "        self.logger.record(\"penalties/rew_depth\",           sum(self.rew_depth)/len(self.rew_depth))\n",
    "        \n",
    "        self.pen_M, self.pen_B, self.pen_P, self.pen_reg = [], [], [], []\n",
    "        self.n_pen_M, self.n_pen_B, self.n_pen_P, self.n_pen_Q, self.pen_nv, self.pen_nv_counted = [], [], [], [], [], []\n",
    "        self.units_sold, self.units_bought, self.rew_sold, self.rew_depth = [], [], [], []\n",
    "        \n",
    "        # this_model_name = self.model_name + datetime.now().strftime('%m%d-%H%M%S')\n",
    "        # self.perfs[this_model_name] = safe_mean([ep_info[\"r\"] for ep_info in model.ep_info_buffer])\n",
    "        # self.model.save(this_model_name)\n",
    "        \n",
    "        \n",
    "    def _on_step(self) -> bool:\n",
    "        log_std: th.Tensor = self.model.policy.log_std\n",
    "        t = self.locals[\"infos\"][0]['dict_state']['t']\n",
    "        \n",
    "        if self.locals[\"infos\"][0][\"terminated\"] or self.locals[\"infos\"][0][\"truncated\"]: # record info at each episode end\n",
    "            self.pen_M.append(self.locals[\"infos\"][0][\"pen_tracker\"][\"M\"])\n",
    "            self.pen_B.append(self.locals[\"infos\"][0][\"pen_tracker\"][\"B\"])\n",
    "            self.pen_P.append(self.locals[\"infos\"][0][\"pen_tracker\"][\"P\"])\n",
    "            \n",
    "            self.n_pen_M.append(self.locals[\"infos\"][0][\"pen_tracker\"][\"n_M\"])\n",
    "            self.n_pen_B.append(self.locals[\"infos\"][0][\"pen_tracker\"][\"n_B\"])\n",
    "            self.n_pen_P.append(self.locals[\"infos\"][0][\"pen_tracker\"][\"n_P\"])\n",
    "            self.n_pen_Q.append(self.locals[\"infos\"][0][\"pen_tracker\"][\"n_Q\"])\n",
    "            self.pen_nv.append(self.locals[\"infos\"][0][\"pen_tracker\"][\"n_M\"] +\n",
    "                               self.locals[\"infos\"][0][\"pen_tracker\"][\"n_B\"] +\n",
    "                               self.locals[\"infos\"][0][\"pen_tracker\"][\"n_Q\"] +\n",
    "                               self.locals[\"infos\"][0][\"pen_tracker\"][\"n_P\"])\n",
    "            self.pen_nv_counted.append(self.locals[\"infos\"][0][\"pen_tracker\"][\"n_M\"] if cfg[\"env\"][\"M\"] > 0 else 0 +\n",
    "                                       self.locals[\"infos\"][0][\"pen_tracker\"][\"n_B\"] if cfg[\"env\"][\"B\"] > 0 else 0 +\n",
    "                                       self.locals[\"infos\"][0][\"pen_tracker\"][\"n_Q\"] if cfg[\"env\"][\"Q\"] > 0 else 0 +\n",
    "                                       self.locals[\"infos\"][0][\"pen_tracker\"][\"n_P\"] if cfg[\"env\"][\"P\"] > 0 else 0)\n",
    "            # print(self.pen_nv, self.pen_nv_counted, self.n_pen_M, self.n_pen_B, self.n_pen_P)\n",
    "            self.units_sold.append(self.locals[\"infos\"][0][\"pen_tracker\"][\"units_sold\"])\n",
    "            self.units_bought.append(self.locals[\"infos\"][0][\"pen_tracker\"][\"units_bought\"])\n",
    "            self.rew_sold.append(self.locals[\"infos\"][0][\"pen_tracker\"][\"rew_sold\"])\n",
    "            self.rew_depth.append(self.locals[\"infos\"][0][\"pen_tracker\"][\"rew_depth\"])\n",
    "        \n",
    "        if self.v:\n",
    "            if self.num_timesteps%5000 < 6 and t == 1: # start printing\n",
    "                self.print_flag = True\n",
    "                \n",
    "            if self.print_flag:\n",
    "                if self.v == \"text\":\n",
    "                    print(\"\\nt:\", t)\n",
    "                    if np.isnan(self.locals['rewards'][0]) or np.isinf(self.locals['rewards'][0]):\n",
    "                        print(f\"is invalid reward {self.locals['rewards'][0]}\")\n",
    "                    for i in ['obs_tensor', 'clipped_actions', 'rewards']:\n",
    "                        if i in self.locals:\n",
    "                            print(f\"{i}: \" + str(self.locals[i]))\n",
    "                    \n",
    "\n",
    "                elif self.v == \"img\":\n",
    "                    try:\n",
    "                        img = self.training_env.get_attr(\"render\")[0]()\n",
    "                        pil_image = Image.fromarray(img)\n",
    "                        pil_image.save(f\"{model_name.replace('models', 'logs2')}_0/img/{self.num_timesteps}_{t}.png\")\n",
    "                        \n",
    "                    except FileNotFoundError:\n",
    "                        os.mkdir(os.path.join(os.getcwd(), f\"{model_name.replace('models', 'logs2')}_0/img\"))\n",
    "                \n",
    "                if t == 6:\n",
    "                    self.print_flag = False\n",
    "                    print(f\"\\n\\nLog-Std at step {self.num_timesteps}: {log_std.detach().cpu().numpy()}\")\n",
    "                    print(self.locals[\"infos\"][0][\"pen_tracker\"])\n",
    "                    print(\"\\n\\n\\n\\n\\n\")\n",
    "        \n",
    "        if self.std_control:\n",
    "            progress = self.current_step / self.schedule_timesteps\n",
    "            new_log_std = self.start_log_std + progress * (self.end_log_std - self.start_log_std)\n",
    "            self.model.policy.log_std.data.fill_(new_log_std)\n",
    "            self.current_step += 1\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\adame\\\\OneDrive\\\\Bureau\\\\CODE\\\\BlendingRL'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/simple/61-72/65/65_1225-1535'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_timesteps = 1e5\n",
    "log_callback = CustomLoggingCallbackPPO(schedule_timesteps=total_timesteps, \n",
    "                                        std_control = cfg[\"clipped_std\"],\n",
    "                                        model_name = model_name, \n",
    "                                        v = \"img\") if optimizer_cls == PPO else CustomLoggingCallbackDDPG()\n",
    "callback = CallbackList([log_callback])\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging at simple/61-72/65/65_1225-1535\n",
      "\n",
      "\n",
      "Log-Std at step 6: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "{'M': -120, 'B': -70.69430910050869, 'P': -9.59325310921998, 'Q': 0, 'n_M': 12, 'n_B': 17, 'n_P': 3, 'n_Q': 0, 'units_sold': 0.0, 'units_bought': 6.6315078139305115, 'rew_sold': 0.0, 'rew_depth': 7.935308179591971, 'rew_bought': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Log-Std at step 5010: [ 0.01100536  0.00716582  0.01837818  0.01416336 -0.0116841   0.01679907\n",
      "  0.00834745  0.01354424 -0.00936338  0.01154996  0.01022923  0.01095804\n",
      "  0.01747564  0.01549258  0.02031877 -0.00291336  0.01864661  0.00682647\n",
      "  0.01520657  0.018809  ]\n",
      "{'M': -10, 'B': -57.29678297042847, 'P': -99.55651724338531, 'Q': 0, 'n_M': 1, 'n_B': 6, 'n_P': 13, 'n_Q': 0, 'units_sold': 0.0, 'units_bought': 36.54814672470093, 'rew_sold': 0.0, 'rew_depth': 35.355886340141296, 'rew_bought': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Log-Std at step 10008: [ 0.01831699  0.0123056   0.0318554   0.01898001 -0.00406772  0.02410472\n",
      "  0.00346603  0.00282144  0.00093009  0.01825056  0.02407469  0.02798827\n",
      "  0.01931692  0.03436985  0.00845531 -0.00448823  0.0317486  -0.00238623\n",
      "  0.02708648  0.04099929]\n",
      "{'M': -60, 'B': -2801.6912050415212, 'P': -1683.7906703948975, 'Q': 0, 'n_M': 6, 'n_B': 24, 'n_P': 12, 'n_Q': 0, 'units_sold': 0.0, 'units_bought': 118.77752375182678, 'rew_sold': 0.0, 'rew_depth': 0, 'rew_bought': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Log-Std at step 15006: [0.04524912 0.05339951 0.06801338 0.05847571 0.02149864 0.06358487\n",
      " 0.02272422 0.02978054 0.02188678 0.05780669 0.0545287  0.05661217\n",
      " 0.03988479 0.07249707 0.02123104 0.03128574 0.07240855 0.00469228\n",
      " 0.05590691 0.0927444 ]\n",
      "{'M': -20, 'B': -8121.1400513733, 'P': -14897.783203125, 'Q': 0, 'n_M': 2, 'n_B': 24, 'n_P': 22, 'n_Q': 0, 'units_sold': 0.0, 'units_bought': 118.77752375182678, 'rew_sold': 0.0, 'rew_depth': 117.74758743819763, 'rew_bought': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Log-Std at step 20010: [0.07019164 0.0866888  0.0995106  0.09419987 0.04871972 0.10784479\n",
      " 0.04367268 0.05273496 0.03975809 0.09911383 0.08608428 0.08760277\n",
      " 0.06519224 0.11067647 0.03660601 0.0691245  0.11225961 0.01231917\n",
      " 0.08217783 0.15102397]\n",
      "{'M': -60, 'B': -5098.000006692521, 'P': -5913.708023071289, 'Q': 0, 'n_M': 6, 'n_B': 24, 'n_P': 12, 'n_Q': 0, 'units_sold': 0.0, 'units_bought': 118.77752375182678, 'rew_sold': 0.0, 'rew_depth': 0, 'rew_bought': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Log-Std at step 25008: [0.25679597 0.26823363 0.27617985 0.32580268 0.22285149 0.3612946\n",
      " 0.1850435  0.1863927  0.1762517  0.31514865 0.27874005 0.25631237\n",
      " 0.24333224 0.34006444 0.13647488 0.29457152 0.33220452 0.07099122\n",
      " 0.2640971  0.40679905]\n",
      "{'M': -10, 'B': -66.46873009204865, 'P': -259.4186057448387, 'Q': 0, 'n_M': 1, 'n_B': 13, 'n_P': 12, 'n_Q': 0, 'units_sold': 0.0, 'units_bought': 38.27054309844971, 'rew_sold': 0.0, 'rew_depth': 66.44443738460541, 'rew_bought': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Log-Std at step 30006: [0.28180024 0.36304495 0.3234911  0.36953387 0.36968264 0.4391192\n",
      " 0.30573282 0.2366584  0.20581456 0.32786518 0.3909066  0.34092122\n",
      " 0.300569   0.46082756 0.15111846 0.42901438 0.36491972 0.13905539\n",
      " 0.27255246 0.4165025 ]\n",
      "{'M': 0, 'B': -1955.4484176803762, 'P': -1089.4638037597572, 'Q': 0, 'n_M': 0, 'n_B': 30, 'n_P': 11, 'n_Q': 0, 'units_sold': 0.0, 'units_bought': 118.77752375182678, 'rew_sold': 0.0, 'rew_depth': 237.55504750365355, 'rew_bought': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Log-Std at step 35010: [0.323965   0.45234707 0.39541543 0.42409927 0.506334   0.49329102\n",
      " 0.3701044  0.31281883 0.26539916 0.37149677 0.45460954 0.42147747\n",
      " 0.3676038  0.5411079  0.1876113  0.46930215 0.3902215  0.19819243\n",
      " 0.30207857 0.44763994]\n",
      "{'M': 0, 'B': -10307.601132409685, 'P': -4543.703118842909, 'Q': 0, 'n_M': 0, 'n_B': 42, 'n_P': 11, 'n_Q': 0, 'units_sold': 0.0, 'units_bought': 118.77752375182678, 'rew_sold': 0.0, 'rew_depth': 237.55504750365358, 'rew_bought': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Log-Std at step 40008: [0.34663606 0.49809778 0.42762232 0.45145857 0.5723437  0.5205864\n",
      " 0.40357128 0.35199624 0.2945029  0.3926805  0.481248   0.46279627\n",
      " 0.40618178 0.57824546 0.20460166 0.49506912 0.403262   0.22842866\n",
      " 0.31716374 0.464945  ]\n",
      "{'M': 0, 'B': -6003.230341004245, 'P': -4763.668852849036, 'Q': 0, 'n_M': 0, 'n_B': 42, 'n_P': 11, 'n_Q': 0, 'units_sold': 0.0, 'units_bought': 118.77752375182678, 'rew_sold': 0.0, 'rew_depth': 237.55504750365358, 'rew_bought': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Log-Std at step 45006: [0.3930709  0.5903025  0.4951721  0.501271   0.6992412  0.57301533\n",
      " 0.46769714 0.42958397 0.35509613 0.443979   0.55058306 0.5445353\n",
      " 0.48329702 0.654823   0.24821548 0.5367678  0.42941898 0.29176214\n",
      " 0.34733194 0.5016772 ]\n",
      "{'M': -60, 'B': -1135.1181383300952, 'P': -1358.1839141845703, 'Q': 0, 'n_M': 6, 'n_B': 26, 'n_P': 6, 'n_Q': 0, 'units_sold': 0.0, 'units_bought': 118.77752375182678, 'rew_sold': 0.0, 'rew_depth': 0, 'rew_bought': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Log-Std at step 50010: [0.5058868  0.75785714 0.5840761  0.58924335 0.77897954 0.66284376\n",
      " 0.5384057  0.48999768 0.4081256  0.55570376 0.6598064  0.68235964\n",
      " 0.643676   0.7731048  0.33257094 0.64798737 0.49246317 0.42665002\n",
      " 0.39756498 0.54503715]\n",
      "{'M': -60, 'B': -129.67494350671768, 'P': -80.78232535719872, 'Q': 0, 'n_M': 6, 'n_B': 20, 'n_P': 10, 'n_Q': 0, 'units_sold': 0.0, 'units_bought': 17.91872012615204, 'rew_sold': 0.0, 'rew_depth': 23.12891127485947, 'rew_bought': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Log-Std at step 55008: [0.5580949  0.7006851  0.5721466  0.6058041  0.8085981  0.7113723\n",
      " 0.6128319  0.50452316 0.53246903 0.5831508  0.6945519  0.68099993\n",
      " 0.58254707 0.7720015  0.34289408 0.6252768  0.4563957  0.44066286\n",
      " 0.37191322 0.41080034]\n",
      "{'M': -40, 'B': -78.02941906452179, 'P': -70.54888907074928, 'Q': 0, 'n_M': 4, 'n_B': 13, 'n_P': 11, 'n_Q': 0, 'units_sold': 0.0, 'units_bought': 9.636896848678589, 'rew_sold': 0.0, 'rew_depth': 13.025652468204498, 'rew_bought': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Log-Std at step 60006: [0.5452971  0.6718473  0.5531234  0.59698087 0.8009386  0.70822114\n",
      " 0.59483784 0.5104173  0.5367319  0.5532238  0.6768411  0.6713428\n",
      " 0.5850482  0.77804816 0.3564395  0.6293001  0.4666601  0.44608805\n",
      " 0.34852505 0.41586074]\n",
      "{'M': -60, 'B': -63.827886878334795, 'P': -54.14429053553275, 'Q': 0, 'n_M': 6, 'n_B': 15, 'n_P': 7, 'n_Q': 1, 'units_sold': 1.7949581412557216, 'units_bought': 11.708662033081055, 'rew_sold': 179.49581412557217, 'rew_depth': 19.79699921147766, 'rew_bought': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Log-Std at step 65010: [0.5518375  0.6572071  0.5568246  0.5753027  0.8044484  0.7111928\n",
      " 0.579291   0.51007193 0.50762886 0.53283113 0.6724055  0.66126615\n",
      " 0.59300053 0.7635415  0.33884427 0.64245117 0.46972927 0.44689223\n",
      " 0.34220538 0.4155752 ]\n",
      "{'M': -50, 'B': -60.405142536614434, 'P': -58.01069128091724, 'Q': 0, 'n_M': 5, 'n_B': 10, 'n_P': 10, 'n_Q': 1, 'units_sold': 1.5217281476387892, 'units_bought': 10.918348625302315, 'rew_sold': 152.1728147638789, 'rew_depth': 22.266631359299474, 'rew_bought': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m logpath \u001b[38;5;241m=\u001b[39m model_name[\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;124m\"\u001b[39m):]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogging at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\blendv2\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\blendv2\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:300\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 300\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\blendv2\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:224\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    221\u001b[0m             terminal_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mpredict_values(terminal_obs)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    222\u001b[0m         rewards[idx] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m terminal_value\n\u001b[1;32m--> 224\u001b[0m \u001b[43mrollout_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_last_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_last_episode_starts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;241m=\u001b[39m new_obs  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_episode_starts \u001b[38;5;241m=\u001b[39m dones\n",
      "File \u001b[1;32mc:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\blendv2\\lib\\site-packages\\stable_baselines3\\common\\buffers.py:474\u001b[0m, in \u001b[0;36mRolloutBuffer.add\u001b[1;34m(self, obs, action, reward, episode_start, value, log_prob)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(reward)\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_starts[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(episode_start)\n\u001b[1;32m--> 474\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos] \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_probs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos] \u001b[38;5;241m=\u001b[39m log_prob\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logpath = model_name[len(\"models/\"):]\n",
    "print(f\"logging at {logpath}\")\n",
    "model.learn(total_timesteps = total_timesteps,\n",
    "            progress_bar = False,\n",
    "            tb_log_name = logpath,\n",
    "            callback = callback,\n",
    "            reset_num_timesteps = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def save_next_file(directory, model_name):\n",
    "    base_pattern = re.compile(model_name + r\"_(\\d+)\\.zip\")\n",
    "    \n",
    "    try:\n",
    "        files = os.listdir(directory)\n",
    "    except:\n",
    "        os.mkdir(directory)\n",
    "        \n",
    "        files = os.listdir(directory)\n",
    "        \n",
    "    max_number = 0\n",
    "    for file in files:\n",
    "        match = base_pattern.match(file)\n",
    "        if match:\n",
    "            number = int(match.group(1))\n",
    "            max_number = max(max_number, number)\n",
    "    \n",
    "    # Generate the next filename\n",
    "    next_file_number = max_number + 1\n",
    "    next_file_name = f\"{model_name}_{next_file_number}\"\n",
    "    next_file_path = os.path.join(directory, next_file_name)\n",
    "    \n",
    "    model.save(next_file_path)\n",
    "    \n",
    "save_next_file(os.path.dirname(model_name), os.path.basename(model_name) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"models\\\\simplest\\\\25-36\\\\30\\\\30_0930-1359_1.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M,Q,P,B,Z,D = 10, 0, 5, 5, 1, 0\n",
    "M, Q, P, B, Z, D  = cfg[\"env\"][\"M\"], cfg[\"env\"][\"Q\"], cfg[\"env\"][\"P\"], cfg[\"env\"][\"B\"], cfg[\"env\"][\"Z\"], 0\n",
    "# M,Q,P,B,Z,D = 0, 0, 0, 0, 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg[\"env\"][\"uniform_data\"]:\n",
    "    tau0   = {s: [np.random.binomial(1, 0.7) * np.random.normal(15, 2) for _ in range(20)] for s in sources}\n",
    "    delta0 = {d: [np.random.binomial(1, 0.7) * np.random.normal(15, 2) for _ in range(20)] for d in demands}\n",
    "else:\n",
    "    tau0   = {s: [10, 10, 10, 0, 0, 0] for s in sources}\n",
    "    delta0 = {d: [0, 0, 0, 10, 10, 10] for d in demands}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BlendEnv(v = True, \n",
    "               D = cfg[\"env\"][\"D\"], \n",
    "               Q = cfg[\"env\"][\"Q\"], \n",
    "               P = cfg[\"env\"][\"P\"], \n",
    "               B = cfg[\"env\"][\"B\"], \n",
    "               Z = cfg[\"env\"][\"Z\"], \n",
    "               M = cfg[\"env\"][\"M\"],\n",
    "               reg = cfg[\"env\"][\"reg\"],\n",
    "               reg_lambda = cfg[\"env\"][\"reg_lambda\"],\n",
    "               MAXFLOW = cfg[\"env\"][\"maxflow\"],\n",
    "               alpha = cfg[\"env\"][\"alpha\"],\n",
    "               beta = cfg[\"env\"][\"beta\"],\n",
    "               connections = connections, \n",
    "               action_sample = action_sample,\n",
    "               tau0 = tau0,delta0 = delta0,\n",
    "               sigma = sigma,\n",
    "               sigma_ub = sigma_ub, sigma_lb = sigma_lb,\n",
    "               s_inv_lb = s_inv_lb, s_inv_ub = s_inv_ub,\n",
    "               d_inv_lb = d_inv_lb, d_inv_ub = d_inv_ub,\n",
    "               betaT_d = betaT_d, betaT_s = betaT_s,\n",
    "               b_inv_ub = b_inv_ub,\n",
    "               b_inv_lb = b_inv_lb)\n",
    "env = Monitor(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " {'M': 0, 'B': 0, 'P': 0, 'Q': 0, 'reg': 0, 'n_violations': 0}\n",
      "[ 2.2490938  0.        10.549076   0.       ]\n",
      "\n",
      "\n",
      "    {'source_blend': {'s1': {'j1': 2.2490938}}, 'blend_demand': {'j1': {'p1': 0.0}}, 'tau': {'s1': 10.549076}, 'delta': {'p1': 0.0}}\n",
      "Increased reward by 8.29998230934143 through tank population in s1\n",
      "j1: inv: 0, in_flow_sources: 2.249093770980835, in_flow_blend: 0, out_flow_blend: 0, out_flow_demands: 0.0\n",
      "Increased reward by 4.49818754196167 through tank population in j1\n",
      "Increased reward by 0 through tank population in p1\n",
      "[ 8.299982   2.2490938  0.         0.06      19.031122  17.232286\n",
      " 12.631584  20.010368  13.486182  11.07766   16.463406   0.\n",
      " 17.160105   0.        16.847889   0.         1.       ]\n",
      "\n",
      "    >>      {'s1': 8.299982} {'j1': 2.2490938} {'p1': 0.0}\n",
      "    10.449076080322266\n",
      "\n",
      "\n",
      " {'M': 0, 'B': 0, 'P': 0, 'Q': 0, 'reg': 0, 'n_violations': 0}\n",
      "[5.444898  0.        3.9590578 0.       ]\n",
      "\n",
      "\n",
      "    {'source_blend': {'s1': {'j1': 5.444898}}, 'blend_demand': {'j1': {'p1': 0.0}}, 'tau': {'s1': 3.9590578}, 'delta': {'p1': 0.0}}\n",
      "Increased reward by 0 through tank population in s1\n",
      "j1: inv: 2.249093770980835, in_flow_sources: 5.4448981285095215, in_flow_blend: 0, out_flow_blend: 0, out_flow_demands: 0.0\n",
      "Increased reward by 10.889796257019043 through tank population in j1\n",
      "Increased reward by 0 through tank population in p1\n",
      "[ 6.814142    7.6939917   0.          0.10246091 12.631584   20.010368\n",
      " 13.486182   11.07766    16.463406    0.         17.160105    0.\n",
      " 16.847889    0.          0.         15.201728    2.        ]\n",
      "\n",
      "    >>      {'s1': 6.814142} {'j1': 7.6939917} {'p1': 0.0}\n",
      "    15.793974208831788\n",
      "\n",
      "\n",
      " {'M': 0, 'B': 0, 'P': 0, 'Q': 0, 'reg': 0, 'n_violations': 0}\n",
      "[0.        5.281314  0.9563463 0.       ]\n",
      "\n",
      "\n",
      "    {'source_blend': {'s1': {'j1': 0.0}}, 'blend_demand': {'j1': {'p1': 5.281314}}, 'tau': {'s1': 0.9563463}, 'delta': {'p1': 0.0}}\n",
      "Increased reward by 0.9563462734222412 through tank population in s1\n",
      "j1: inv: 7.6939918994903564, in_flow_sources: 0.0, in_flow_blend: 0, out_flow_blend: 0, out_flow_demands: 5.281313896179199\n",
      "Increased reward by 0 through tank population in j1\n",
      "Increased reward by 21.125255584716797 through tank population in p1\n",
      "[PEN] t3; p1; q1; j1:\t\t\tSold qualities out of bounds (-0.12)\n",
      "[ 7.7704883  2.412678   5.281314  -0.1218244 13.486182  11.07766\n",
      " 16.463406   0.        17.160105   0.        16.847889   0.\n",
      "  0.        15.201728  10.047319  15.311101   3.       ]\n",
      "\n",
      "    >>      {'s1': 7.7704883} {'j1': 2.412678} {'p1': 5.281314}\n",
      "    32.49426217079163\n",
      "\n",
      "\n",
      " {'M': 0, 'B': 0, 'P': 0, 'Q': 0, 'reg': 0, 'n_violations': 1}\n",
      "[0.         0.47993773 2.0407162  0.        ]\n",
      "\n",
      "\n",
      "    {'source_blend': {'s1': {'j1': 0.0}}, 'blend_demand': {'j1': {'p1': 0.47993773}}, 'tau': {'s1': 2.0407162}, 'delta': {'p1': 0.0}}\n",
      "Increased reward by 2.0407161712646484 through tank population in s1\n",
      "j1: inv: 2.4126780033111572, in_flow_sources: 0.0, in_flow_blend: 0, out_flow_blend: 0, out_flow_demands: 0.47993773221969604\n",
      "Increased reward by 0 through tank population in j1\n",
      "Increased reward by 1.9197509288787842 through tank population in p1\n",
      "[PEN] t4; p1; q1; j1:\t\t\tSold qualities out of bounds (-0.09)\n",
      "[ 9.811205    1.9327402   5.7612514  -0.09157299 16.463406    0.\n",
      " 17.160105    0.         16.847889    0.          0.         15.201728\n",
      " 10.047319   15.311101   14.976164   17.884268    4.        ]\n",
      "\n",
      "    >>      {'s1': 9.811205} {'j1': 1.9327402} {'p1': 5.7612514}\n",
      "    35.874791538715364\n",
      "\n",
      "\n",
      " {'M': 0, 'B': 0, 'P': 0, 'Q': 0, 'reg': 0, 'n_violations': 2}\n",
      "[0.         0.         0.6370637  0.22133237]\n",
      "\n",
      "\n",
      "    {'source_blend': {'s1': {'j1': 0.0}}, 'blend_demand': {'j1': {'p1': 0.0}}, 'tau': {'s1': 0.6370637}, 'delta': {'p1': 0.22133237}}\n",
      "[PEN] t5; p1:\t\t\tsold too much (more than demand)\n",
      "Increased reward by 0.6370636820793152 through tank population in s1\n",
      "j1: inv: 1.9327402710914612, in_flow_sources: 0.0, in_flow_blend: 0, out_flow_blend: 0, out_flow_demands: 0.0\n",
      "Increased reward by 0 through tank population in j1\n",
      "Increased reward by 0 through tank population in p1\n",
      "[10.448268    1.9327402   5.7612514  -0.09157299 17.160105    0.\n",
      " 16.847889    0.          0.         15.201728   10.047319   15.311101\n",
      " 14.976164   17.884268   12.588721   14.116285    5.        ]\n",
      "\n",
      "    >>      {'s1': 10.448268} {'j1': 1.9327402} {'p1': 5.7612514}\n",
      "    -63.48814477920533\n",
      "\n",
      "\n",
      " {'M': 0, 'B': -100, 'P': 0, 'Q': 0, 'reg': 0, 'n_violations': 3}\n",
      "[0.        0.        3.8217669 2.2020528]\n",
      "\n",
      "\n",
      "    {'source_blend': {'s1': {'j1': 0.0}}, 'blend_demand': {'j1': {'p1': 0.0}}, 'tau': {'s1': 3.8217669}, 'delta': {'p1': 2.2020528}}\n",
      "[PEN] t6; p1:\t\t\tsold too much (more than demand)\n",
      "Increased reward by 3.8217668533325195 through tank population in s1\n",
      "j1: inv: 1.9327402710914612, in_flow_sources: 0.0, in_flow_blend: 0, out_flow_blend: 0, out_flow_demands: 0.0\n",
      "Increased reward by 0 through tank population in j1\n",
      "Increased reward by 0 through tank population in p1\n",
      "[14.270035    1.9327402   5.7612514  -0.09157299 16.847889    0.\n",
      "  0.         15.201728   10.047319   15.311101   14.976164   17.884268\n",
      " 12.588721   14.116285    0.         15.300578    6.        ]\n",
      "\n",
      "    >>      {'s1': 14.270035} {'j1': 1.9327402} {'p1': 5.7612514}\n",
      "    -159.6663779258728\n"
     ]
    }
   ],
   "source": [
    "with th.autograd.set_detect_anomaly(True):\n",
    "    obs = env.reset()\n",
    "    obs, obs_dict = obs\n",
    "    for k in range(env.T):\n",
    "        action, _ = model.predict(obs, deterministic=False)\n",
    "        print(\"\\n\\n\",env.pen_tracker)\n",
    "        print(action)\n",
    "        print(\"\\n\\n   \",reconstruct_dict(action, env.mapping_act))\n",
    "        obs, reward, done, term, _ = env.step(action)\n",
    "        print(obs)\n",
    "        dobs = reconstruct_dict(obs, env.mapping_obs)\n",
    "        print(\"\\n    >>     \",dobs[\"sources\"], dobs[\"blenders\"], dobs[\"demands\"])\n",
    "        print(\"   \" ,reward)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 (only once per episode)\n",
    "episode_rewards = []\n",
    "obs = env.reset()\n",
    "obs, obs_dict = obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# 1 Get first action\n",
    "print(env.t)\n",
    "action, _ = model.predict(obs, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'s1': 17.46205}\n",
      "{'j1': 0.0}\n",
      "{'p1': 0.0}\n",
      "{'j1': {'q1': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "print(env.t)\n",
    "d = reconstruct_dict(obs, env.mapping_obs)\n",
    "print(d[\"sources\"])\n",
    "print(d[\"blenders\"])\n",
    "print(d[\"demands\"])\n",
    "print(d[\"properties\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'source_blend': {'s1': {'j1': 0.0}},\n",
       " 'blend_demand': {'j1': {'p1': 30.307917}},\n",
       " 'tau': {'s1': 8.731916},\n",
       " 'delta': {'p1': 17.08481}}"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 Visualize action\n",
    "print(env.t)\n",
    "reconstruct_dict(action, env.mapping_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "# Step once: get 2nd action\n",
    "print(env.t)\n",
    "obs, reward, done, term, _ = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{'s1': 26.193966}\n",
      "{'j1': 0.0}\n",
      "{'p1': 0.0}\n",
      "{'j1': {'q1': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "# 4 Visualize new state\n",
    "print(env.t)\n",
    "d = reconstruct_dict(obs, env.mapping_obs)\n",
    "print(d[\"sources\"])\n",
    "print(d[\"blenders\"])\n",
    "print(d[\"demands\"])\n",
    "print(d[\"properties\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blendv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
