{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "try:\n",
    "    os.chdir(curr_dir)\n",
    "except:\n",
    "    curr_dir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "    os.chdir(curr_dir)\n",
    "    print(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from envs import BlendEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\blendv2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(curr_dir, \"decision-transformer\\\\gym\\\\\"))\n",
    "from decision_transformer.models.decision_transformer import DecisionTransformer\n",
    "os.chdir(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adame\\AppData\\Local\\Temp\\ipykernel_9304\\3768740294.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dict = th.load(\"./trained_dt.pth\")\n"
     ]
    }
   ],
   "source": [
    "model_dict = th.load(\"./trained_dt.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml, json\n",
    "with open(\"./configs/30.yaml\", \"r\") as f:\n",
    "    s = \"\".join(f.readlines())\n",
    "    cfg = yaml.load(s, Loader=yaml.FullLoader)\n",
    "    \n",
    "layout = \"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./configs/json/connections_{layout}.json\" ,\"r\") as f:\n",
    "    connections_s = f.readline()\n",
    "connections = json.loads(connections_s)\n",
    "\n",
    "with open(f\"./configs/json/action_sample_{layout}.json\" ,\"r\") as f:\n",
    "    action_sample_s = f.readline()\n",
    "action_sample = json.loads(action_sample_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sbp(connections):\n",
    "    sources = list(connections[\"source_blend\"].keys())\n",
    "    \n",
    "    b_list = list(connections[\"blend_blend\"].keys())\n",
    "    for b in connections[\"blend_blend\"].keys():\n",
    "        b_list += connections[\"blend_blend\"][b]\n",
    "    b_list += list(connections[\"blend_demand\"].keys())\n",
    "    blenders = list(set(b_list))\n",
    "    \n",
    "    p_list = []\n",
    "    for p in connections[\"blend_demand\"].keys():\n",
    "        p_list += connections[\"blend_demand\"][p]\n",
    "    demands = list(set(p_list))\n",
    "    \n",
    "    return sources, blenders, demands\n",
    "sources, blenders, demands = get_sbp(connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 6\n",
    "if layout == \"base\":\n",
    "    sigma = {\"s1\":{\"q1\": 0.06}, \"s2\":{\"q1\": 0.26}}\n",
    "    sigma_ub = {\"p1\":{\"q1\": 0.16}, \"p2\":{\"q1\": 1}}\n",
    "    sigma_lb = {\"p1\":{\"q1\": 0}, \"p2\":{\"q1\": 0}}\n",
    "else:\n",
    "    sigma = {s:{\"q1\": 0.06} for s in sources}\n",
    "    sigma_ub = {d:{\"q1\": 0.16} for d in demands}\n",
    "    sigma_lb = {d:{\"q1\": 0} for d in demands}\n",
    "    \n",
    "s_inv_lb = {s: 0 for s in sources}\n",
    "s_inv_ub = {s: 999 for s in sources}\n",
    "d_inv_lb = {d: 0 for d in demands}\n",
    "d_inv_ub = {d: 999 for d in demands}\n",
    "betaT_d = {d: 1 for d in demands} # Price of sold products\n",
    "b_inv_ub = {j: 30 for j in blenders} \n",
    "b_inv_lb = {j: 0 for j in blenders}\n",
    "betaT_s = {s: cfg[\"env\"][\"product_cost\"]  for s in sources} # Cost of bought products\n",
    "\n",
    "if cfg[\"env\"][\"uniform_data\"]:\n",
    "    if cfg[\"env\"][\"max_pen_violations\"] < 999:\n",
    "        max_ep_length = 50\n",
    "        tau0   = {s: [np.random.normal(20, 3) for _ in range(max_ep_length)] for s in sources}\n",
    "        delta0 = {d: [np.random.normal(20, 3) for _ in range(max_ep_length)] for d in demands}\n",
    "        T = max_ep_length\n",
    "        \n",
    "    else:\n",
    "        tau0   = {s: [np.random.normal(20, 3) for _ in range(13)] for s in sources}\n",
    "        delta0 = {d: [np.random.normal(20, 3) for _ in range(13)] for d in demands}\n",
    "else:\n",
    "    tau0   = {s: [10, 10, 10, 0, 0, 0] for s in sources}\n",
    "    delta0 = {d: [0, 0, 0, 10, 10, 10] for d in demands}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "M,Q,P,B,Z,D = 0, 0, 0, 0, 1, 0\n",
    "env = BlendEnv(v = True, \n",
    "               D = D, \n",
    "               Q = Q, \n",
    "               P = P, \n",
    "               B = B, \n",
    "               Z = Z, \n",
    "               M = M,\n",
    "               reg = cfg[\"env\"][\"reg\"],\n",
    "               reg_lambda = cfg[\"env\"][\"reg_lambda\"],\n",
    "               MAXFLOW = cfg[\"env\"][\"maxflow\"],\n",
    "               alpha = cfg[\"env\"][\"alpha\"],\n",
    "               beta = cfg[\"env\"][\"beta\"],\n",
    "               connections = connections, \n",
    "               action_sample = action_sample,\n",
    "               tau0 = tau0,delta0 = delta0,\n",
    "               sigma = sigma,\n",
    "               sigma_ub = sigma_ub, sigma_lb = sigma_lb,\n",
    "               s_inv_lb = s_inv_lb, s_inv_ub = s_inv_ub,\n",
    "               d_inv_lb = d_inv_lb, d_inv_ub = d_inv_ub,\n",
    "               betaT_d = betaT_d, betaT_s = betaT_s,\n",
    "               b_inv_ub = b_inv_ub,\n",
    "               b_inv_lb = b_inv_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTransformer(\n",
    "            state_dim=env.observation_space.shape[0],\n",
    "            act_dim=env.action_space.shape[0],\n",
    "            max_length=20,\n",
    "            max_ep_len=12,\n",
    "            hidden_size=128,\n",
    "            n_layer=3,\n",
    "            n_head=1,\n",
    "            n_inner=4*128,\n",
    "            activation_function='relu',\n",
    "            n_positions=1024,\n",
    "            resid_pdrop=0.1,\n",
    "            attn_pdrop=0.1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"C:/Users/adame/OneDrive/Bureau/CODE/BlendingRL/decision-transformer/gym/data/blend-medium-v4.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['observations', 'next_observations', 'actions', 'rewards', 'dones'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        , 25.9       ,  0.        ,\n",
       "         0.        , 12.9       , 25.1       ,  0.        , 19.5       ,\n",
       "        14.5       , 11.6       , 12.3       , 18.7       , 13.5       ,\n",
       "         0.        , 21.7       , 16.        ,  0.        , 11.9       ,\n",
       "         0.        , 23.5       ,  0.        ,  0.        , 13.4       ,\n",
       "        20.6       ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        25.9       ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.26      , 12.9       , 25.1       ,  0.        ,\n",
       "        19.5       , 14.5       , 11.6       , 12.3       , 18.7       ,\n",
       "        13.5       ,  0.        , 21.7       , 16.        ,  0.        ,\n",
       "        11.9       ,  0.        , 23.5       ,  0.        ,  0.        ,\n",
       "        13.4       , 20.6       ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.6       , 12.17582646, 12.92417354,  0.        , 12.3       ,\n",
       "         0.        ,  0.        , 25.9       ,  0.26000003,  0.        ,\n",
       "         0.05999998,  0.26      , 14.5       , 11.6       , 12.3       ,\n",
       "        18.7       , 13.5       ,  0.        , 21.7       , 16.        ,\n",
       "         0.        , 11.9       ,  0.        , 23.5       ,  0.        ,\n",
       "         0.        , 13.4       , 20.6       ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  2.        ],\n",
       "       [ 0.        ,  8.7       ,  0.        , 30.17582646,  0.        ,\n",
       "         0.        ,  0.        , 20.12417354,  0.25999997,  0.1599199 ,\n",
       "         0.05999993,  0.        , 13.5       ,  0.        , 21.7       ,\n",
       "        16.        ,  0.        , 11.9       ,  0.        , 23.5       ,\n",
       "         0.        ,  0.        , 13.4       , 20.6       ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  3.        ],\n",
       "       [ 0.        ,  8.7       ,  0.        ,  0.        , 13.5       ,\n",
       "         0.        ,  8.47582646, 14.92417354,  0.        ,  0.1599199 ,\n",
       "         0.05999999,  0.        ,  0.        , 11.9       ,  0.        ,\n",
       "        23.5       ,  0.        ,  0.        , 13.4       , 20.6       ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  4.        ],\n",
       "       [ 0.        ,  0.        , 20.6       ,  0.        ,  4.92417354,\n",
       "         0.        ,  8.47582646,  0.        ,  0.26      ,  0.        ,\n",
       "         0.05999997,  0.        ,  0.        ,  0.        , 13.4       ,\n",
       "        20.6       ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  5.        ]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][\"observations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[161.0483],\n",
       "        [161.1483],\n",
       "        [161.4483],\n",
       "        [118.5483],\n",
       "        [ 70.1483],\n",
       "        [ 46.8483]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.Tensor(data[0][\"rewards\"]).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 3 is not equal to len(dims) = 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobservations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mactions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrewards\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrewards\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLongTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adame\\OneDrive\\Bureau\\CODE\\BlendingRL\\decision-transformer\\gym\\decision_transformer\\models\\decision_transformer.py:75\u001b[0m, in \u001b[0;36mDecisionTransformer.forward\u001b[1;34m(self, states, actions, rewards, returns_to_go, timesteps, attention_mask)\u001b[0m\n\u001b[0;32m     71\u001b[0m returns_embeddings \u001b[38;5;241m=\u001b[39m returns_embeddings \u001b[38;5;241m+\u001b[39m time_embeddings\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# this makes the sequence look like (R_1, s_1, a_1, R_2, s_2, a_2, ...)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# which works nice in an autoregressive sense since states predict actions\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m stacked_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturns_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     77\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(batch_size, \u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mseq_length, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[0;32m     78\u001b[0m stacked_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_ln(stacked_inputs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# to make the attention mask fit the stacked inputs, have to stack it as well\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 3 is not equal to len(dims) = 4"
     ]
    }
   ],
   "source": [
    "model.forward(th.Tensor(data[0][\"observations\"]), th.Tensor(data[0][\"actions\"]), th.Tensor(data[0][\"rewards\"]), th.Tensor(data[0][\"rewards\"]).unsqueeze(1), th.LongTensor(np.arange(6)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blendv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
